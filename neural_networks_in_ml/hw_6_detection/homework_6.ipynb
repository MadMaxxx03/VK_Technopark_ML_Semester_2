{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Lfm2SHHrKO"
   },
   "source": [
    "## Домашнее задание: \"Детекция объектов на изображении\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBi6uhznYZc_"
   },
   "source": [
    "ФИО:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bAjQPD3H50I"
   },
   "source": [
    "## Цель задания:\n",
    "Научиться самостоятельно решать задачу детекции.\n",
    "## Описание задания:\n",
    "В рамках данного домашнего задания предлагается решить задачу детекции мячей и настроить полный пайплайн обучения модели. \n",
    "\n",
    "Процесс выполнения задания следующий:\n",
    "\n",
    "0. Выбор модели детекции для обучения:\n",
    "    1. Выберите модель детекции для выполнения домашнего задания. Любую, кроме RetinaNet. Ее реализацию можно взять из открытых источников. Модель можно брать предобученную ( в этом случае в пункте 4. показать влияние предобучения на финальное качество). \n",
    "    2. Полезные ссылки: [PyTorch Vision Models](https://pytorch.org/vision/stable/models.html) (блок Object Detection), [SOTA модели детекции](https://paperswithcode.com/sota/object-detection-on-coco), [Возможный пример кода](https://github.com/AlekseySpasenov/dl-course/blob/autumn_2023/lecture8/detection_example/pytorch_detection_workshop.ipynb)\n",
    "\n",
    "1. Подготовка обучающего набора данных\n",
    "    1. Реализуйте корректный класс Dataset и Dataloader для выбранной модели (должен работать форвард вашей модели на том, что выходит из даталоадера) **0.5 балла**.\n",
    "    2. Добавьте простые аугментации в датасет (аугментации, не затрагивающие изменение ground-truth bounding box) **0.5 балла**.\n",
    "    3. Внедрите сложные аугментации (аугментации, затрагивающие изменение ground-truth bounding box. Например, аффинные преобразования: сдвиг, поворот и т.д.) **0.5 балла**.\n",
    "\n",
    "    4. Полезные ссылки: https://pytorch.org/vision/stable/transforms.html , https://albumentations.ai\n",
    "\n",
    "2. Реализация корректного train-loop и обучение модели:  \n",
    "    1. Реализуйте эффективный train-loop для вашей модели и проведите обучение **2 балла**.\n",
    "    2. Выполните несколько запусков обучения с различными параметрами, например: сравните влияние различных аугментаций, оцените влияние того была предобучена модель или нет, сравните результаты при изменении гиперпараметров итд (на ваш выбор) **0.5 балла**.\n",
    " \n",
    "3. Валидация обученных моделей на тестовой выборке, вычисление метрики mAP\n",
    "    1. Оцените качество моделей на тестовой части данных и рассчитайте метрику mAP **0.5 балл**\n",
    "    2. Полезные ссылки: [mean_average_precision](https://github.com/bes-dev/mean_average_precision)\n",
    "\n",
    "4. Выводы **0.5 балл**:\n",
    "    1. Проанализируйте результаты обучения, визуально оцените качество работы модели.\n",
    "    2. Прокомментируйте распространенные ошибки модели и предложите пути для улучшения финального решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1235396348.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    посчемуто до запуска твоей команды у меня работал вывод изображения\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "посчемуто до запуска твоей команды у меня работал вывод изображения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m----> 2\u001b[0m images_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m labels_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_image_with_bbox\u001b[39m(image_path, label_path):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/train'  \n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "labels_dir = os.path.join(data_dir, 'labels')\n",
    "\n",
    "def visualize_image_with_bbox(image_path, label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img_h, img_w, _ = image.shape\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = list(map(float, line.split()))\n",
    "        class_id = int(parts[0])  \n",
    "        points = parts[1:] \n",
    "\n",
    "        x1, y1 = int(points[0] * img_w), int(points[1] * img_h)\n",
    "        x2, y2 = int(points[2] * img_w), int(points[3] * img_h)\n",
    "        x3, y3 = int(points[4] * img_w), int(points[5] * img_h)\n",
    "        x4, y4 = int(points[6] * img_w), int(points[7] * img_h)\n",
    "\n",
    "        pts = [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n",
    "        pts = np.array(pts, np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        \n",
    "        cv2.polylines(image, [pts], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "image_files = os.listdir(images_dir)\n",
    "label_files = os.listdir(labels_dir)\n",
    "\n",
    "image_basenames = [os.path.splitext(f)[0] for f in image_files]\n",
    "label_basenames = [os.path.splitext(f)[0] for f in label_files]\n",
    "\n",
    "for image_file, image_base in zip(image_files, image_basenames):\n",
    "    if image_base in label_basenames:\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        label_path = os.path.join(labels_dir, image_base + '.txt')\n",
    "        \n",
    "        visualize_image_with_bbox(image_path, label_path)\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Файл разметки для {image_file} не найден.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "тут "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
